{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zam3ivRlXNMl"
      },
      "source": [
        "# **Extract (E)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xnC6qGcE_Ke5"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NYr867n6D_lQ"
      },
      "outputs": [],
      "source": [
        "log_file = \"log_file.txt\"\n",
        "target_file = \"transformed_data_filter_develop_inloco.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tevl_EpHa0wQ"
      },
      "outputs": [],
      "source": [
        "def log_progress(message):\n",
        "    with open(log_file, \"a\") as f:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        f.write(f\"{timestamp} - {message}\\n\")\n",
        "    print(f\"{timestamp} - {message}\")  # Para debug no console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sJByjzRNUk15"
      },
      "outputs": [],
      "source": [
        "def extract_from_csv(file_to_process):\n",
        "    dataframe = pd.read_csv(file_to_process, sep=\";\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gU6Cr5D1WW4U"
      },
      "outputs": [],
      "source": [
        "def extract():\n",
        "    # Criar um DataFrame vazio apenas com as colunas desejadas\n",
        "    extracted_data = pd.DataFrame(columns=['SYMBOL', 'DESCRIPTION', 'PRODUCT', 'REGION'])\n",
        "\n",
        "    # Caminho dos arquivos CSV\n",
        "    csv_path = \"/content/*.csv\"\n",
        "\n",
        "    for csvfile in glob.glob(csv_path):\n",
        "        temp_df = extract_from_csv(csvfile)\n",
        "\n",
        "        # Manter apenas as colunas desejadas (ignorar extras)\n",
        "        temp_df = temp_df[['SYMBOL', 'DESCRIPTION', 'PRODUCT', 'REGION']]\n",
        "\n",
        "        # Concatenar apenas essas colunas ao DataFrame final\n",
        "        extracted_data = pd.concat([extracted_data, temp_df], ignore_index=True)\n",
        "\n",
        "    return extracted_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5x_kWZwXTme"
      },
      "source": [
        "# **Transform (T)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HQ7-jQj2XXjW"
      },
      "outputs": [],
      "source": [
        "def transform(data):\n",
        "    if \"SYMBOL\" in data.columns:\n",
        "        data[\"SYMBOL\"] = data[\"SYMBOL\"].str.upper()\n",
        "    else:\n",
        "        print(\"Aviso: Coluna 'SYMBOL' n√£o encontrada no DataFrame.\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA9ovEnKX9T3"
      },
      "source": [
        "# **Loading and Logging (L)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SXT4iesDYN7E"
      },
      "outputs": [],
      "source": [
        "def load_data(target_file, transformed_data):\n",
        "    transformed_data.to_csv(target_file, index=False, encoding=\"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4FLAMS7ZcIg"
      },
      "source": [
        "LOGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k1fyIhOZd3a",
        "outputId": "1a6c9a50-b49e-4efd-9dd5-16b135f2296e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-19 20:19:08 - ETL Job Started\n",
            "2025-02-19 20:19:08 - Extract phase Started\n",
            "2025-02-19 20:19:08 - Extract phase Ended\n",
            "2025-02-19 20:19:08 - Transform phase Started\n",
            "Transformed Data\n",
            "     SYMBOL                   DESCRIPTION PRODUCT REGION\n",
            "0      9840        SPDR GOLD SHARES - USD     ETF     US\n",
            "1       AAA  ALTERNATIVE ACCESS FIRST PRI     ETF     US\n",
            "2      AAAU   GOLDMAN SACHS PHYSICAL GOLD     ETF     US\n",
            "3      AADR   ADVISORSHARES DORSEY WRIGHT     ETF     US\n",
            "4      AAPB  GRANITESHARES 2X LONG AAPL D     ETF     US\n",
            "...     ...                           ...     ...    ...\n",
            "5296    ZWT   BMO COVERED CALL TECHNOLOGY     ETF     CA\n",
            "5297    ZWU  BMO COVERED CALL UTILITIES E     ETF     CA\n",
            "5298    ZXM  CI MORNINGSTAR INTL MOMENTUM     ETF     CA\n",
            "5299  ZXM.B  CI MORNINGSTAR INTL MOMENT-B     ETF     CA\n",
            "5300   ZZZD  BMO TACTICAL DIV ETF FD ETFS     ETF     CA\n",
            "\n",
            "[5301 rows x 4 columns]\n",
            "2025-02-19 20:19:08 - Transform phase Ended\n",
            "2025-02-19 20:19:08 - Load phase Started\n",
            "2025-02-19 20:19:08 - Load phase Ended\n",
            "2025-02-19 20:19:08 - ETL Job Ended\n"
          ]
        }
      ],
      "source": [
        "# Log the initialization of the ETL process\n",
        "log_progress(\"ETL Job Started\")\n",
        "\n",
        "# Log the beginning of the Extraction process\n",
        "log_progress(\"Extract phase Started\")\n",
        "extracted_data = extract()\n",
        "\n",
        "# Log the completion of the Extraction process\n",
        "log_progress(\"Extract phase Ended\")\n",
        "\n",
        "# Log the beginning of the Transformation process\n",
        "log_progress(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "print(\"Transformed Data\")\n",
        "print(transformed_data)\n",
        "\n",
        "# Log the completion of the Transformation process\n",
        "log_progress(\"Transform phase Ended\")\n",
        "\n",
        "# Log the beginning of the Loading process\n",
        "log_progress(\"Load phase Started\")\n",
        "load_data(target_file,transformed_data)\n",
        "\n",
        "# Log the completion of the Loading process\n",
        "log_progress(\"Load phase Ended\")\n",
        "\n",
        "# Log the completion of the ETL process\n",
        "log_progress(\"ETL Job Ended\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}